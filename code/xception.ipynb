{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "plant-seedlings-classification.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I5AI3AMIvtpA"
      ]
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3yeQecRDJTY"
      },
      "source": [
        "# CZ/CE 4041 Machine Learning\n",
        "\n",
        "## Plant Seedling Classification [Kaggle]\n",
        "\n",
        "### Approach 5: Xception\n",
        "\n",
        "### Team\n",
        "* Dwivedee Lakshyajeet\n",
        "* Gupta Jay\n",
        "* Bansal Aditya\n",
        "* Mantri Raghav\n",
        "* Bhatia Ritik\n",
        "\n",
        "> **Warning:** This notebook was created on the Google Colaboratory platform where it fetches data from Google Drive which must be uploaded by the user. It will not work by default on the Jupyter Notebook Platform."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcIHMDIwvto6"
      },
      "source": [
        "### 1. Importing dependencies and creating configuration variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Xgh5-K58vto8"
      },
      "source": [
        "import os # For fetching files\n",
        "import cv2 # Image segmentation, sharpening, etc.\n",
        "import numpy as np # Data manipulation\n",
        "from tqdm import tqdm # Tracking progress while iterating over files\n",
        "import matplotlib.pyplot as plt # Showing sample images\n",
        "\n",
        "# Importing neural network related functions from TensorFlow and Keras\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import *\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "from keras.utils import to_categorical\n",
        "from keras.applications.xception import *\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout, Dense, Flatten, GlobalAveragePooling2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "SciunoRdvto_"
      },
      "source": [
        "# Defining classification labels\n",
        "labels = ['Black-grass',\n",
        "          'Charlock',\n",
        "          'Cleavers',\n",
        "          'Common Chickweed',\n",
        "          'Common wheat',\n",
        "          'Fat Hen',\n",
        "          'Loose Silky-bent',\n",
        "          'Maize',\n",
        "          'Scentless Mayweed',\n",
        "          'Shepherds Purse',\n",
        "          'Small-flowered Cranesbill',\n",
        "          'Sugar beet']\n",
        "\n",
        "# Enable/Disable data manipulation\n",
        "GEN_DATA = True # True if data needs to be preprocessed and stored in Drive\n",
        "UNZIP = False    # True if only zipped file stored in Drive\n",
        "\n",
        "# Version of the model being trained\n",
        "DATA_VERSION = \"\"  # Change if new version of preprocessed data needs to be saved\n",
        "SAVE_VERSION = \"2\" # Change if new version of model and output needs to be saved\n",
        "\n",
        "# Defining data paths\n",
        "DATA_DIR = 'drive/My Drive/plant-seedlings-classification' # Root directory for all content related to project (can be changed to local address)\n",
        "TRAIN_SEG_PATH = f'{DATA_DIR}/train_seg{DATA_VERSION}'     # Directory where segmented training data is stored\n",
        "TEST_SEG_PATH = f'{DATA_DIR}/test_seg{DATA_VERSION}'       # Directory where segmented testing data is stored\n",
        "\n",
        "# Path to store models and submissions\n",
        "SUBMISSION_PATH = f'{DATA_DIR}/submission{SAVE_VERSION}.csv' # Path to store submission data\n",
        "\n",
        "# Defining model hyperparameters\n",
        "IMG_SIZE = 299         # Size of image to be fed into model\n",
        "BATCH_SIZE = 16        # Batch size during training\n",
        "TRAIN_IMG_COUNT = 4750 # Number of images in training set\n",
        "EPOCHS = 30            # Epochs to train for\n",
        "MODEL_COUNT = 3        # Number of models to train (increase if ensembling on different trained instances of model is needed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49PNbfElJMY0"
      },
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTXKt3cZLgOV"
      },
      "source": [
        "# Unzipping the data if not already done\n",
        "if UNZIP:\n",
        "  ! unzip -uq \"drive/MyDrive/plant-seedlings-classification/test.zip\" -d \"drive/MyDrive/plant-seedlings-classification/test\"\n",
        "  ! unzip -uq \"drive/MyDrive/plant-seedlings-classification/train.zip\" -d \"drive/MyDrive/plant-seedlings-classification/train\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5AI3AMIvtpA"
      },
      "source": [
        "### 2. Segmenting the images\n",
        "\n",
        "We iterate through all train and test set images and store their segmented versions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UB3Kfi7-vtpB"
      },
      "source": [
        "# For generating a plant-mask based on HSV values\n",
        "def create_mask(img): \n",
        "  # Bounds for segmenting based on colour\n",
        "  lower_bound = np.array([25, 100, 50])\n",
        "  upper_bound = np.array([95, 255, 255])\n",
        "\n",
        "  kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11)) # Defining kernel for dilation and erosion for noisy border removal\n",
        "\n",
        "  img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV) # Converting from RGB to HSV form\n",
        "  segment_mask = cv2.inRange(img_hsv, lower_bound, upper_bound) # Segment image into mask\n",
        "  segment_mask = cv2.morphologyEx(segment_mask, cv2.MORPH_CLOSE, kernel) # Smoothen noisy borders\n",
        "\n",
        "  return segment_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "FfM0zYvvvtpC"
      },
      "source": [
        "# For segmenting image based on HSV mask\n",
        "def segment(img):\n",
        "  mask = create_mask(img) # Get mask from previous step\n",
        "  masked_img = cv2.bitwise_and(img, img, mask=mask) # Keep image where mask=1, change to black where mask=0\n",
        "  return masked_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "EIXdc_yTvtpC"
      },
      "source": [
        "# For sharpening the segmented image\n",
        "def sharpen(img):\n",
        "  img_blur = cv2.GaussianBlur(img, (0,0), 3) # Get blurred version of image\n",
        "  img_sharp = cv2.addWeighted(img, 1.5, img_blur, -0.5, 0) # Subtract blurred version from original (1.5 - 0.5 = 1 = original brightness)\n",
        "  return img_sharp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_seOB4c_vtpE"
      },
      "source": [
        "# For segmenting training set images\n",
        "if GEN_DATA:\n",
        "  # Creating the folder to save segmented training images\n",
        "  if not os.path.isdir(TRAIN_SEG_PATH):\n",
        "      os.mkdir(TRAIN_SEG_PATH) # Create directory for segmented training images\n",
        "      \n",
        "  f, axarr = plt.subplots(1,2) # For showing a sample image\n",
        "\n",
        "  # Segmenting the training data       \n",
        "  for idx, label in enumerate(labels):\n",
        "\n",
        "    folder = os.path.join(DATA_DIR, \"train\", label) # Get path to label folder\n",
        "\n",
        "    show_img = True\n",
        "    for img_name in tqdm(os.listdir(folder)): # Iterate through images in training set\n",
        "      img_path = os.path.join(folder, img_name) # Get path to current image\n",
        "      img = cv2.imread(img_path, cv2.IMREAD_COLOR) # Read image\n",
        "      img_seg = segment(img) # Get segmented image\n",
        "      img_sharp = sharpen(img_seg) # Sharpen segmented image\n",
        "      seg_path = os.path.join(TRAIN_SEG_PATH, label) # Get path to save segmented image\n",
        "\n",
        "      if not os.path.isdir(seg_path):\n",
        "        os.mkdir(seg_path) # Create directory for label in segmented training images folder\n",
        "\n",
        "      cv2.imwrite(os.path.join(seg_path, img_name), img_sharp) # Save image\n",
        "\n",
        "      # Plotting a sample\n",
        "      if show_img:\n",
        "        show_img = False\n",
        "        axarr[0].imshow(img)\n",
        "        axarr[1].imshow(img_seg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NpPuwLwWvtpF"
      },
      "source": [
        "# For segmenting test set images\n",
        "if GEN_DATA:\n",
        "  # Creating the folder to save segmented testing images\n",
        "  if not os.path.isdir(TEST_SEG_PATH):\n",
        "      os.mkdir(TEST_SEG_PATH) # Create directory for segmented test images\n",
        "  \n",
        "  # Segmenting the test data  \n",
        "  folder = os.path.join(DATA_DIR, \"test\") # Get path to test set folder\n",
        "\n",
        "  for img_name in tqdm(os.listdir(folder)): # Iterate through images in test set\n",
        "    img_path = os.path.join(folder, img_name) # Get path to current image\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_COLOR) # Read image\n",
        "    img_seg = segment(img) # Get segmented image\n",
        "    img_sharp = sharpen(img_seg) # Sharpen segmented image\n",
        "    cv2.imwrite(os.path.join(TEST_SEG_PATH, img_name), img_sharp) # Save image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKBY_QXCvtpG"
      },
      "source": [
        "### 3. Training our base models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7qgSJQmCvtph"
      },
      "source": [
        "# Creating a data generator with data augmentation rules\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess_input, # Necessary preprocessing for Xception model\n",
        "                             height_shift_range=0.3,                  # Change image height by ±0.3\n",
        "                             horizontal_flip=True,                    # Randomly flip image horizontally\n",
        "                             rotation_range=180,                      # Rotate image ±180°\n",
        "                             vertical_flip=True,                      # Randomly flip image vertically\n",
        "                             width_shift_range=0.3,                   # Change image width ±0.3\n",
        "                             zoom_range=0.3)                          # Change image zoom ±0.3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ROD0JoSxvtph"
      },
      "source": [
        "# For defining and compiling the model\n",
        "def create_model():\n",
        "  initial_model = Xception(weights='imagenet', \n",
        "                           input_shape=(IMG_SIZE, IMG_SIZE, 3), \n",
        "                           include_top=False)  # Get the original Xception model without dense layers\n",
        "  x = initial_model.output                     # Get the output of the Xception model\n",
        "  x = GlobalAveragePooling2D()(x)              # Use global average pooling for spatially averaging each feature map\n",
        "  x = Dropout(0.5)(x)                          # 50% probability dropout to prevent overfitting\n",
        "  x = Dense(1024, activation='relu')(x)        # Dense layer with 1024 neurons and ReLU activation function\n",
        "  x = Dropout(0.5)(x)                          # 50% probability dropout to prevent overfitting\n",
        "  outputs = Dense(12, activation='softmax')(x) # Dense layer with len(labels) = 12 neurons and softmax activation function\n",
        "  model = Model(inputs=initial_model.input, outputs=outputs) # Create model based on Xception inputs and custom output layers\n",
        "\n",
        "  model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy']) # Compile model\n",
        "  \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTkzKEigPVyM"
      },
      "source": [
        "# Generating our list of model instances (based on MODEL_COUNT)\n",
        "models = []\n",
        "for i in range(MODEL_COUNT):\n",
        "  model = create_model()\n",
        "  models.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PV5ajnLGPZ-Z"
      },
      "source": [
        "# Initializing the data generator for feeding data to model\n",
        "train_gen = datagen.flow_from_directory(TRAIN_SEG_PATH,                  # Path where segmented training images are stored\n",
        "                                       target_size=(IMG_SIZE, IMG_SIZE), # Dimension all images are scaled to before being fed into model\n",
        "                                       batch_size=BATCH_SIZE,            # Number of images to feed per batch\n",
        "                                       class_mode='categorical')         # Type of model output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHx3fvEf6Q7Z"
      },
      "source": [
        "# Defining the learning rate scheduler function\n",
        "def scheduler(epoch, lr):\n",
        "  print(f\"Learning Rate: {lr}\")\n",
        "  if epoch < 6: # If less than 6 epochs, use original learning rate\n",
        "    return lr\n",
        "  else: # If 6th epoch or more, multiply current learning rate by 0.9\n",
        "    return lr*0.9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bDHr-denvtpi"
      },
      "source": [
        "# Training the models\n",
        "histories = [] # For storing model training history\n",
        "\n",
        "for i in range(MODEL_COUNT):\n",
        "  model_path = f'{DATA_DIR}/Xception{SAVE_VERSION}_{i}.h5' # Destination where model must be saved\n",
        "\n",
        "  lr_callback = LearningRateScheduler(scheduler) # Defining learning rate scheduler callback\n",
        "\n",
        "  # Defining the checkpoint saving callback (saves the weights of the best model till 30 steps)\n",
        "  ckpt_callback = ModelCheckpoint(\n",
        "      filepath=model_path,                        # Where model weights will be saved\n",
        "      save_weights_only=True,                     # Save weights instead of entire model details\n",
        "      monitor='accuracy',                         # Metric to decide whether to update saved weights\n",
        "      mode='max',                                 # Save max of previous and current accuracy\n",
        "      save_freq=TRAIN_IMG_COUNT//(10*BATCH_SIZE), # How often to save = every 30 steps\n",
        "      save_best_only=True)                        # Only save the best model's weights till now\n",
        "\n",
        "  print(f\"=== Model Number: {i+1} ===\")\n",
        "  history = models[i].fit(train_gen,                         # Using previously defined training data generator\n",
        "                          steps_per_epoch=TRAIN_IMG_COUNT//BATCH_SIZE, # Number of steps in each epoch\n",
        "                          epochs=EPOCHS,                               # Number of total epochs\n",
        "                          callbacks=[lr_callback, ckpt_callback],      # Callbacks to use - learning rate scheduler and checkpoint saver\n",
        "                          verbose=1)                                   # Print training logs at verbosity level 1\n",
        "  histories.append(history) # Append training history to list of histories"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFv2PiDq0zwE"
      },
      "source": [
        "# Plotting model training set accuracies vs. epochs\n",
        "fig, axs = plt.subplots(MODEL_COUNT, figsize=(6,8), constrained_layout=True)\n",
        "\n",
        "for i in range(MODEL_COUNT):\n",
        "  axs[i].plot(histories[i].history['accuracy'], label=\"Train\")\n",
        "  axs[i].set_title(f'Model Accuracy vs. Epochs ({i})')\n",
        "  axs[i].set_ylabel('Accuracy')\n",
        "  axs[i].set_xlabel('Epoch')\n",
        "  axs[i].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln1NGgSt3EpI"
      },
      "source": [
        "# Plotting model training set losses vs. epochs\n",
        "fig, axs = plt.subplots(MODEL_COUNT, figsize=(6,8), constrained_layout=True)\n",
        "\n",
        "for i in range(MODEL_COUNT):\n",
        "  axs[i].plot(histories[i].history['loss'], label=\"Train\")\n",
        "  axs[i].set_title(f'Model Loss vs. Epochs ({i})')\n",
        "  axs[i].set_ylabel('Loss')\n",
        "  axs[i].set_xlabel('Epoch')\n",
        "  axs[i].legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnCHDsS0vtpi"
      },
      "source": [
        "### 4. Running model on test set and saving the submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UmGRruZRvtpk"
      },
      "source": [
        "# Loading the model weights\n",
        "models = []\n",
        "\n",
        "for i in range(MODEL_COUNT):\n",
        "  model = create_model()\n",
        "\n",
        "  model_path = f'{DATA_DIR}/Xception{SAVE_VERSION}_{i}.h5'\n",
        "  model.load_weights(model_path)\n",
        "  models.append(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBMMQnK5kuZU"
      },
      "source": [
        "# Running the models on the test sets and saving the submission file\n",
        "with open(SUBMISSION_PATH, 'w') as f: # Open path for saving submission CSV\n",
        "\n",
        "  f.write('file,species\\n') # Write headers to CSV\n",
        "\n",
        "  for img_name in tqdm(os.listdir(TEST_SEG_PATH)): # Iterate through each image in the test set\n",
        "    img = image.load_img(\n",
        "        os.path.join(TEST_SEG_PATH, img_name), \n",
        "        target_size=(IMG_SIZE, IMG_SIZE))      # Load current image and scale to size required by model\n",
        "    input = image.img_to_array(img)            # Convert image to numpy array\n",
        "    input = np.expand_dims(input, axis=0)      # Add a dimension at 0th index        \n",
        "    model_pred = np.zeros([MODEL_COUNT], dtype=\"int64\") # Create placeholder for each model's predictions\n",
        "    for i in range(MODEL_COUNT): # Iterate through each of our trained models\n",
        "      model = models[i]\n",
        "      probs = np.zeros([12,]) # Create placeholder for predictions (size = [12,1])\n",
        "      for augmentation_count, img_augmented in enumerate(datagen.flow(input)): # Iterate through each version of image after test set augmentation\n",
        "        probs += model.predict(img_augmented)[0] # Add probability for each label to probs placeholder\n",
        "        if augmentation_count > 100: # Quit prediction for this image if more than 100 augmentation instances\n",
        "          break\n",
        "      model_pred[i] =  int(np.where(probs == np.max(probs))[0][0]) # Get the prediction for current model\n",
        "\n",
        "    try:\n",
        "      f.write('{},{}\\n'.format(img_name, labels[np.bincount(model_pred).argmax()]) ) # Use voting to select label which was most predicted\n",
        "    except: # If all models give a different output\n",
        "      used_first += 1\n",
        "      f.write('{},{}\\n'.format(img_name, labels[model_pred[0]]) ) # Use first model's output"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}