{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CZ/CE 4041 Machine Learning\n",
    "\n",
    "## Plant Seedling Classification [Kaggle]\n",
    "\n",
    "### Approach 6: Inception - ResNet - v2\n",
    "\n",
    "### Team\n",
    "* Dwivedee Lakshyajeet\n",
    "* Gupta Jay\n",
    "* Bansal Aditya\n",
    "* Mantri Raghav\n",
    "* Bhatia Ritik\n",
    "\n",
    "> **Warning:** This notebook was created on the Google Colaboratory platform where it fetches data from Google Drive which must be uploaded by the user. It will not work by default on the Jupyter Notebook Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify imports to be used in the notebook\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the training data directory\n",
    "TRAIN_DATA_DIR = '../input/plant-seedlings-classification/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the classes of the plants\n",
    "species = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \"Common wheat\", \"Fat Hen\",\n",
    "                \"Loose Silky-bent\", \"Maize\", \"Scentless Mayweed\", \"Shepherds Purse\", \"Small-flowered Cranesbill\",\n",
    "                \"Sugar beet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns the model with custom layers appended\n",
    "def define_model(width, height):\n",
    "    \n",
    "    # define the input to the model\n",
    "    input_model = tf.keras.layers.Input(shape = (width, height, 3), name = 'image_input')\n",
    "    \n",
    "    # main model with Incpetion - ResNet - v2 layers\n",
    "    # omit the top layers as we are adding custom layers\n",
    "    # use transfer learning, with weights from Imagenet trained model\n",
    "    main_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top = False, weights = 'imagenet')(input_model)\n",
    "    \n",
    "    # flatten model to get appropriate dimensions\n",
    "    flattened_model = tf.keras.layers.Flatten()(main_model)\n",
    "    \n",
    "    # add custom dropout and dense layers\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.5)(flattened_model)\n",
    "    dense_1 = tf.keras.layers.Dense(128, activation = 'relu', activity_regularizer=tf.keras.regularizers.l2(1e-5))(dropout_1)\n",
    "    dropout_2 = tf.keras.layers.Dropout(0.5)(dense_1)\n",
    "    \n",
    "    # output of model\n",
    "    output_model = tf.keras.layers.Dense(12, activation = \"softmax\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(dropout_2)\n",
    "\n",
    "    model = tf.keras.models.Model(input_model,  output_model)\n",
    "    \n",
    "    # use Adam optimizer with model\n",
    "    optimizer = tf.keras.optimizers.Adam(lr = 5e-4, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    \n",
    "    # use categorical crossentropy loss since classification task\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define appropriate callbacks\n",
    "def training_callbacks():\n",
    "    \n",
    "    # save best model regularly\n",
    "    save_best_model = tf.keras.callbacks.ModelCheckpoint(filepath = 'model.h5',\n",
    "        monitor = 'loss', save_best_only = True, verbose = 1)\n",
    "    \n",
    "    # reduce learning rate when it stops decreasing\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', factor = 0.4,\n",
    "                              patience = 3, min_lr = 1e-10, verbose = 1, cooldown = 1)\n",
    "    \n",
    "    # stop training early if no further improvement\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'loss', min_delta = 1e-2, patience = 8, verbose = 1,\n",
    "        mode = 'min', baseline = None, restore_best_weights = True\n",
    "    )\n",
    "\n",
    "    return [save_best_model, reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data generators, to feed into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "def data_generators():\n",
    "    \n",
    "    # apply random transformations on training data\n",
    "    train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range = 360,\n",
    "        shear_range = 0.3,\n",
    "        zoom_range = 0.6,\n",
    "        width_shift_range = 0.4,\n",
    "        height_shift_range = 0.4,\n",
    "        vertical_flip = True,\n",
    "        horizontal_flip = True,\n",
    "        validation_split = 1.0,\n",
    "    )\n",
    "    \n",
    "    # define training data generator\n",
    "    train_gen = train_data_generator.flow_from_directory(\n",
    "        directory = TRAIN_DATA_DIR,\n",
    "        target_size = (width, height),\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = \"categorical\",\n",
    "        batch_size = batch_size,\n",
    "        subset = 'training',\n",
    "    )\n",
    "    \n",
    "    # define test data generator\n",
    "    test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "    test_gen = test_data_generator.flow_from_directory(\n",
    "        directory = '../input/plant-seedlings-classification/',\n",
    "        classes = ['test'],\n",
    "        target_size = (width, height),\n",
    "        batch_size = 1,\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = False,\n",
    "        class_mode = 'categorical')\n",
    "    \n",
    "    # define validation data generator\n",
    "    validation_gen = train_data_generator.flow_from_directory(\n",
    "        directory = TRAIN_DATA_DIR,\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = \"categorical\",\n",
    "        target_size = (width, height),\n",
    "        batch_size = batch_size,\n",
    "        subset = 'validation',\n",
    "    )\n",
    "\n",
    "    return train_gen, validation_gen, test_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "height = 299\n",
    "width = 299\n",
    "num_epochs = 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and start training\n",
    "model = define_model(width, height)\n",
    "train_gen, validation_gen, test_gen = data_generators()\n",
    "\n",
    "# the actual training\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    callbacks = training_callbacks()\n",
    "    epochs = num_epochs,\n",
    "    steps_per_epoch = train_gen.samples // batch_size,\n",
    "    validation_data = validation_gen,\n",
    "    validation_steps = validation_gen.samples // batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# get model predictions\n",
    "model_preds = model.predict(test_gen, steps = test_gen.samples)\n",
    "classes = []\n",
    "\n",
    "for data in range(0, model_preds.shape[0]):\n",
    "    pred_index = model_preds[data, :].argmax(axis = -1)\n",
    "    classes += [species[pred_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate submission csv\n",
    "output_predictions = pd.DataFrame()\n",
    "output_predictions['file'] = test_gen.filenames\n",
    "output_predictions['file'] = output_predictions['file'].str.replace(r'test/', '')\n",
    "output_predictions['species'] = classes\n",
    "output_predictions.to_csv('output.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
