{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# specify imports to be used in the notebook\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport os","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# specify the training data directory\nTRAIN_DATA_DIR = '../input/plant-seedlings-classification/train'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# specify the classes of the plants\nspecies = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \"Common wheat\", \"Fat Hen\",\n                \"Loose Silky-bent\", \"Maize\", \"Scentless Mayweed\", \"Shepherds Purse\", \"Small-flowered Cranesbill\",\n                \"Sugar beet\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Defining the Model","metadata":{}},{"cell_type":"code","source":"# function that returns the model with custom layers appended\ndef define_model(width, height):\n    \n    # define the input to the model\n    input_model = tf.keras.layers.Input(shape = (width, height, 3), name = 'image_input')\n    \n    # main model with Incpetion - ResNet - v2 layers\n    # omit the top layers as we are adding custom layers\n    # use transfer learning, with weights from Imagenet trained model\n    main_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top = False, weights = 'imagenet')(model_input)\n    \n    # flatten model to get appropriate dimensions\n    flattened_model = tf.keras.layers.Flatten()(main_model)\n    \n    # add custom dropout and dense layers\n    dropout_1 = tf.keras.layers.Dropout(0.5)(flattened_model)\n    dense_1 = tf.keras.layers.Dense(128, activation = 'relu', activity_regularizer=tf.keras.regularizers.l2(1e-5))(dropout_1)\n    dropout_2 = tf.keras.layers.Dropout(0.5)(dense_1)\n    \n    # output of model\n    output_model = tf.keras.layers.Dense(12, activation = \"softmax\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(dropout_2)\n\n    model = tf.keras.models.Model(input_model,  output_model)\n    \n    # use Adam optimizer with model\n    optimizer = tf.keras.optimizers.Adam(lr = 5e-4, beta_1 = 0.9, beta_2 = 0.999)\n    \n    # use categorical crossentropy loss since classification task\n    model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define appropriate callbacks\ndef training_callbacks():\n    \n    # save best model regularly\n    save_best_model = tf.keras.callbacks.ModelCheckpoint(filepath = 'model.h5',\n        monitor = 'loss', save_best_only = True, verbose = 1)\n    \n    # reduce learning rate when it stops decreasing\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', factor = 0.4,\n                              patience = 3, min_lr = 1e-10, verbose = 1, cooldown = 1)\n    \n    # stop training early if no further improvement\n    early_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor = 'loss', min_delta = 1e-2, patience = 8, verbose = 1,\n        mode = 'min', baseline = None, restore_best_weights = True\n    )\n\n    return [save_best_model, reduce_lr, early_stopping]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Creating data generators, to feed into model","metadata":{}},{"cell_type":"code","source":"# create data generators\ndef data_generators():\n    \n    # apply random transformations on training data\n    train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n        rotation_range = 360,\n        shear_range = 0.3,\n        zoom_range = 0.6,\n        width_shift_range = 0.4,\n        height_shift_range = 0.4,\n        vertical_flip = True,\n        horizontal_flip = True,\n        validation_split = 1.0,\n    )\n    \n    # define training data generator\n    train_gen = train_data_generator.flow_from_directory(\n        directory = TRAIN_DATA_DIR,\n        target_size = (width, height),\n        color_mode = 'rgb',\n        class_mode = \"categorical\",\n        batch_size = batch_size,\n        subset = 'training',\n    )\n    \n    # define test data generator\n    test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n    test_gen = test_data_generator.flow_from_directory(\n        directory = '../input/plant-seedlings-classification/',\n        classes = ['test'],\n        target_size = (width, height),\n        batch_size = 1,\n        color_mode = 'rgb',\n        shuffle = False,\n        class_mode = 'categorical')\n    \n    # define validation data generator\n    validation_gen = train_data_generator.flow_from_directory(\n        directory = TRAIN_DATA_DIR,\n        color_mode = 'rgb',\n        class_mode = \"categorical\",\n        target_size = (width, height),\n        batch_size = batch_size,\n        subset = 'validation',\n    )\n\n    return train_gen, validation_gen, test_gen","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training the model","metadata":{}},{"cell_type":"code","source":"# define training parameters\nheight = 299\nwidth = 299\nnum_epochs = 100\nbatch_size = 16","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define model and start training\nmodel = define_model(width, height)\ntrain_gen, validation_gen, test_gen = data_generators()\n\n# the actual training\nmodel.fit(\n    train_gen,\n    callbacks = training_callbacks()\n    epochs = num_epochs,\n    steps_per_epoch = train_gen.samples // batch_size,\n    validation_data = validation_gen,\n    validation_steps = validation_gen.samples // batch_size,\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Making predictions on test data","metadata":{}},{"cell_type":"code","source":"# get model predictions\nmodel_preds = model.predict(test_gen, steps = test_gen.samples)\nclasses = []\n\nfor data in range(0, model_preds.shape[0]):\n    pred_index = model_preds[data, :].argmax(axis = -1)\n    classes += [species[pred_index]]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate submission csv\noutput_predictions = pd.DataFrame()\noutput_predictions['file'] = test_gen.filenames\noutput_predictions['file'] = output_predictions['file'].str.replace(r'test/', '')\noutput_predictions['species'] = classes\noutput_predictions.to_csv('output.csv', index = False)","metadata":{},"execution_count":null,"outputs":[]}]}