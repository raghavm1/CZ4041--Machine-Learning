{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CZ/CE 4041 Machine Learning\n",
    "## Plant Seedling Classification [Kaggle] \n",
    "### Exploratory Data Analysis\n",
    "\n",
    "### Team\n",
    "* Dwivedee Lakshyajeet\n",
    "* Gupta Jay\n",
    "* Bansal Aditya\n",
    "* Mantri Raghav\n",
    "* Bhatia Ritik\n",
    "\n",
    "> **Warning:** This notebook was created on the Kaggle platform where it fetches data from the Kaggle directories. It will not work by default on the Jupyter Notebook Platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify imports to be used in the notebook\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the training data directory\n",
    "TRAIN_DATA_DIR = '../input/plant-seedlings-classification/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the classes of the plants\n",
    "species = [\"Black-grass\", \"Charlock\", \"Cleavers\", \"Common Chickweed\", \"Common wheat\", \"Fat Hen\",\n",
    "                \"Loose Silky-bent\", \"Maize\", \"Scentless Mayweed\", \"Shepherds Purse\", \"Small-flowered Cranesbill\",\n",
    "                \"Sugar beet\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that returns the model with custom layers appended\n",
    "def define_model(width, height):\n",
    "    \n",
    "    # define the input to the model\n",
    "    input_model = tf.keras.layers.Input(shape = (width, height, 3), name = 'image_input')\n",
    "    \n",
    "    # main model with Incpetion - ResNet - v2 layers\n",
    "    # omit the top layers as we are adding custom layers\n",
    "    # use transfer learning, with weights from Imagenet trained model\n",
    "    main_model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(include_top = False, weights = 'imagenet')(input_model)\n",
    "    \n",
    "    # flatten model to get appropriate dimensions\n",
    "    flattened_model = tf.keras.layers.Flatten()(main_model)\n",
    "    \n",
    "    # add custom dropout and dense layers\n",
    "    dropout_1 = tf.keras.layers.Dropout(0.5)(flattened_model)\n",
    "    dense_1 = tf.keras.layers.Dense(128, activation = 'relu', activity_regularizer=tf.keras.regularizers.l2(1e-5))(dropout_1)\n",
    "    dropout_2 = tf.keras.layers.Dropout(0.5)(dense_1)\n",
    "    \n",
    "    # output of model\n",
    "    output_model = tf.keras.layers.Dense(12, activation = \"softmax\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(dropout_2)\n",
    "\n",
    "    model = tf.keras.models.Model(input_model,  output_model)\n",
    "    \n",
    "    # use Adam optimizer with model\n",
    "    optimizer = tf.keras.optimizers.Adam(lr = 5e-4, beta_1 = 0.9, beta_2 = 0.999)\n",
    "    \n",
    "    # use categorical crossentropy loss since classification task\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer = optimizer, metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define appropriate callbacks\n",
    "def training_callbacks():\n",
    "    \n",
    "    # save best model regularly\n",
    "    save_best_model = tf.keras.callbacks.ModelCheckpoint(filepath = 'model.h5',\n",
    "        monitor = 'loss', save_best_only = True, verbose = 1)\n",
    "    \n",
    "    # reduce learning rate when it stops decreasing\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'loss', factor = 0.4,\n",
    "                              patience = 3, min_lr = 1e-10, verbose = 1, cooldown = 1)\n",
    "    \n",
    "    # stop training early if no further improvement\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor = 'loss', min_delta = 1e-2, patience = 8, verbose = 1,\n",
    "        mode = 'min', baseline = None, restore_best_weights = True\n",
    "    )\n",
    "\n",
    "    return [save_best_model, reduce_lr, early_stopping]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data generators, to feed into model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data generators\n",
    "def data_generators():\n",
    "    \n",
    "    # apply random transformations on training data\n",
    "    train_data_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rotation_range = 360,\n",
    "        shear_range = 0.3,\n",
    "        zoom_range = 0.6,\n",
    "        width_shift_range = 0.4,\n",
    "        height_shift_range = 0.4,\n",
    "        vertical_flip = True,\n",
    "        horizontal_flip = True,\n",
    "        validation_split = 1.0,\n",
    "    )\n",
    "    \n",
    "    # define training data generator\n",
    "    train_gen = train_data_generator.flow_from_directory(\n",
    "        directory = TRAIN_DATA_DIR,\n",
    "        target_size = (width, height),\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = \"categorical\",\n",
    "        batch_size = batch_size,\n",
    "        subset = 'training',\n",
    "    )\n",
    "    \n",
    "    # define test data generator\n",
    "    test_data_generator = tf.keras.preprocessing.image.ImageDataGenerator()\n",
    "    test_gen = test_data_generator.flow_from_directory(\n",
    "        directory = '../input/plant-seedlings-classification/',\n",
    "        classes = ['test'],\n",
    "        target_size = (width, height),\n",
    "        batch_size = 1,\n",
    "        color_mode = 'rgb',\n",
    "        shuffle = False,\n",
    "        class_mode = 'categorical')\n",
    "    \n",
    "    # define validation data generator\n",
    "    validation_gen = train_data_generator.flow_from_directory(\n",
    "        directory = TRAIN_DATA_DIR,\n",
    "        color_mode = 'rgb',\n",
    "        class_mode = \"categorical\",\n",
    "        target_size = (width, height),\n",
    "        batch_size = batch_size,\n",
    "        subset = 'validation',\n",
    "    )\n",
    "\n",
    "    return train_gen, validation_gen, test_gen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training parameters\n",
    "height = 299\n",
    "width = 299\n",
    "num_epochs = 100\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model and start training\n",
    "model = define_model(width, height)\n",
    "train_gen, validation_gen, test_gen = data_generators()\n",
    "\n",
    "# the actual training\n",
    "model.fit(\n",
    "    train_gen,\n",
    "    callbacks = training_callbacks()\n",
    "    epochs = num_epochs,\n",
    "    steps_per_epoch = train_gen.samples // batch_size,\n",
    "    validation_data = validation_gen,\n",
    "    validation_steps = validation_gen.samples // batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# get model predictions\n",
    "model_preds = model.predict(test_gen, steps = test_gen.samples)\n",
    "classes = []\n",
    "\n",
    "for data in range(0, model_preds.shape[0]):\n",
    "    pred_index = model_preds[data, :].argmax(axis = -1)\n",
    "    classes += [species[pred_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate submission csv\n",
    "output_predictions = pd.DataFrame()\n",
    "output_predictions['file'] = test_gen.filenames\n",
    "output_predictions['file'] = output_predictions['file'].str.replace(r'test/', '')\n",
    "output_predictions['species'] = classes\n",
    "output_predictions.to_csv('output.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
