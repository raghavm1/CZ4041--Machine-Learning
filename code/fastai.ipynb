{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# essential imports, to use in the notebook\nfrom fastai import *\nfrom fastai.vision import *\nimport matplotlib.pyplot as plt\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom glob import glob","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f8ed456f786756e9da8481e5e3e502b8f153d148"},"cell_type":"code","source":"# copy input data from Kaggle into current working directory\n!rm -rf input\n!cp -r ../input .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the path for the training data\npath = Path('input/train/')\n\n# variable to store train data directory\nTRAIN_DATA_DIR = 'input/train'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data augmentation for segmenting the images\n# the code below provides the functions for the same\n\ndef create_mask_for_plant(image):\n    # read image, change to HSV\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    sensitivity = 35\n    \n    # Get pixels from image in the following (Hue, Saturation, Lightness) range\n    lower_hsv = np.array([60 - sensitivity, 100, 50])\n    upper_hsv = np.array([60 + sensitivity, 255, 255])\n    \n    # define mask\n    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    \n    return mask\n\n\ndef segment_plant(image):\n    # apply mask to segment the images\n    mask = create_mask_for_plant(image)\n    output = cv2.bitwise_and(image, image, mask = mask)\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply data augmentation functions defined earlier\nfor class_folder_name in os.listdir(TRAIN_DATA_DIR):\n    \n    # define class folder path, that is, the label\n    class_folder_path = os.path.join(TRAIN_DATA_DIR, class_folder_name)\n    \n    # for every image in a class, apply augmentations and save in same directory\n    for image_path in glob(os.path.join(class_folder_path, \"*.png\")):\n        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n        image = segment_plant(image)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        cv2.imwrite(image_path, image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply same data augmentations for test images\nfor image_path in glob(os.path.join(\"input/test\", \"*.png\")):    \n    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n    image = segment_plant(image)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    cv2.imwrite(image_path, image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1772cbf5a21e68c238b14780a326c3e75d88017c"},"cell_type":"code","source":"# define a random seed for all image transformations\nnp.random.seed(123)\n\n# create an image data bunch\nimage_data_bunch = ImageDataBunch.from_folder(path,test = '../test', ds_tfms = get_transforms(), valid_pct = 0.25, size = 299, bs = 16, num_workers = 0)\nimage_data_bunch.normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72abfa1476f75e410d9f1a049b15c557247fc222"},"cell_type":"code","source":"# print classes, for troubleshooting\nprint(image_data_bunch.classes)\nlen(image_data_bunch.classes),image_data_bunch.c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4da04b7819cae4b13230a194a7f45906381eb929"},"cell_type":"code","source":"# show a batch of images\nimage_data_bunch.show_batch(rows = 2, figsize = (7,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"62cceab0e239fb63e338dfb0da079523f183c70a"},"cell_type":"code","source":"# create the convolutional neural network model, with resnet 50 weights\nmodel = create_cnn(image_data_bunch, models.resnet50, metrics = error_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a778db09806ff70d2d93c34697828dbd6e765397"},"cell_type":"code","source":"# find a suitable learning rate and graph it\nmodel.lr_find()\nmodel.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c1ba352389342107525eca2723911d0b1d820296"},"cell_type":"code","source":"# train the model based on learning rate decided above\nmodel.fit_one_cycle(10, slice(5e-2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cac3f373e3d63fda9b8b6e79cbdfc03c9edb57f2"},"cell_type":"code","source":"# save model checkpoint\nmodel.save('version-1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cfbf0da83a0ba5cecc35991a3bb58c9fac838fd3"},"cell_type":"code","source":"# find a suitable learning rate and graph it\nmodel.lr_find()\nmodel.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"04b955da5809cb350b8a7f427ce6ea8096d91e72"},"cell_type":"code","source":"# unfreeze model, train a bit more\nmodel.unfreeze()\nmodel.fit_one_cycle(10, slice(9e-7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d6e02b01aaa24318f5abe1e60677117a104f4189"},"cell_type":"code","source":"# generate new image data bunch, with images of new size\nimage_data_bunch_new = ImageDataBunch.from_folder(path,test = '../test', ds_tfms = get_transforms(), valid_pct = 0.25, size = 350, bs = 16, num_workers = 0)\nimage_data_bunch_new.normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d7531b1703f575dd830a5c0520127f48a7c9d86e"},"cell_type":"code","source":"# define a classification interpreter, based on model trained earlier\ninterpreter = ClassificationInterpretation.from_learner(model)\n\n# print classification report\nprint(metrics.classification_report(interpreter.y_true.numpy(), interpreter.pred_class.numpy(),target_names = image_data_bunch_new.classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4241e21599fc6bd183bb3133e378061f6663128b"},"cell_type":"code","source":"# save model checkpoint\nmodel.save('version-2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86cc38718cc2c998e933b0bd7e4854402cd2927e"},"cell_type":"code","source":"# assign new data bunch to the model\nmodel.data=image_data_bunch_new","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"db9396096ba0e8216443b68868377db22303eca1"},"cell_type":"code","source":"# unfreeze model train further\nmodel.unfreeze()\nmodel.fit_one_cycle(10, max_lr = slice(1e-5,1e-4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21682a5f0b3168a37edb205bb8c0568bf2691150"},"cell_type":"code","source":"# get predictions on the test data\npredictions,y = model.get_preds(ds_type = DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bd822d5a1812c6706853407c4d655a9cb678b53"},"cell_type":"code","source":"predictions = np.argmax(predictions, axis = 1)\nprediction_classes = [image_data_bunch_new.classes[i] for i in predictions]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e13f6e0c8f3b40329919638288b1b9705b4acf9"},"cell_type":"code","source":"# store the results in a file, for submission\nprediction_file = pd.DataFrame({ 'file': os.listdir('input/test'), 'species': prediction_classes })\nprediction_file.to_csv('results.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}